# Metin TabanlÄ± Veri Setleri ile Yapay Zeka Modelleri GeliÅŸtirme

Bu projede, Reddit platformundan alÄ±nan yorumlar Ã¼zerinde doÄŸal dil iÅŸleme (NLP) teknikleri uygulanarak TF-IDF ve Word2Vec gibi vektÃ¶rleÅŸtirme yÃ¶ntemleriyle metin madenciliÄŸi gerÃ§ekleÅŸtirilmiÅŸtir. AmaÃ§, girilen bir futbol yorumu ile anlamsal olarak benzer olan yorumlarÄ± otomatik olarak bulmak ve farklÄ± modellerin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmaktÄ±r.

---

## ğŸ” Proje Ä°Ã§eriÄŸi

- **Veri KaynaÄŸÄ±:** Reddit API (`r/soccer` subreddit)
- **Veri DosyasÄ±:** `reddit_soccer_comments.csv`
- **TemizlenmiÅŸ Veri:** `reddit_soccer_clean_comments.csv` (lemmatized & stemmed)
- **Ã–n Ä°ÅŸleme:** Stopword temizliÄŸi, lowercasing, tokenization, lemmatization, stemming
- **Zipf Analizi:** Ham, lemmatized ve stemmed veriler iÃ§in log-log grafikleri
- **TF-IDF:** `tfidf_lemmatized.csv` ve `tfidf_stemmed.csv`
- **Word2Vec:** Toplam 16 model (â€œCBOWâ€ & â€œSkipGramâ€, window=2/4, dim=100/300, lemma/stem)
- **Model Ã‡Ä±ktÄ±larÄ±:** 18 model Ã¶nerisi `model_outputs.csv` dosyasÄ±nda saklanmÄ±ÅŸtÄ±r
- **GiriÅŸ Yorumu:** `"feck bet penalti favor real madrid"`

---

## ğŸ“ KlasÃ¶r YapÄ±sÄ±
```
.
â”œâ”€â”€ reddit_soccer_comments.csv
â”œâ”€â”€ reddit_soccer_clean_comments.csv
â”œâ”€â”€ tfidf_lemmatized.csv
â”œâ”€â”€ tfidf_stemmed.csv
â”œâ”€â”€ zipf_*.png
â”œâ”€â”€ word2vec_models/
â”‚   â”œâ”€â”€ *.model (16 adet)
â”œâ”€â”€ model_descriptions/
â”‚   â”œâ”€â”€ *.txt
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ model_outputs.csv
â”‚   â”œâ”€â”€ model_average_similarity_scores.csv
â”‚   â”œâ”€â”€ manual_scoring_filled.csv
â”‚   â”œâ”€â”€ model_comparison_scores.csv
â”‚   â”œâ”€â”€ jaccard_matrix.csv
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ veri_cek.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train_16_models.py
â”‚   â”œâ”€â”€ generate_model_descriptions.py
â”‚   â”œâ”€â”€ recommend.py
â”‚   â”œâ”€â”€ compare_models_scores.py
â”‚   â”œâ”€â”€ jaccard_matrix_generator.py
â”‚   â”œâ”€â”€ save_model_table_image.py
```

---

## âš™ KodlarÄ±n AÃ§Ä±klamasÄ±

### `veri_cek.py`
Reddit API kullanarak `r/soccer` subreddit'inden yorumlarÄ± Ã§eker ve `reddit_soccer_comments.csv` dosyasÄ±na kaydeder.

### `preprocess.py`
Ham verileri temizler:
- Noktalama kaldÄ±rma
- KÃ¼Ã§Ã¼k harfe dÃ¶nÃ¼ÅŸÃ¼rme
- Tokenization
- Stopword silme
- Lemmatization / Stemming uygular

### `train_16_models.py`
16 farklÄ± Word2Vec modelini (CBOW vs SkipGram, dim 100/300, window 2/4, lemma/stem) eÄŸitir ve `word2vec_models/` klasÃ¶rÃ¼ne kaydeder.

### `generate_model_descriptions.py`
Her `.model` dosyasÄ± iÃ§in aynÄ± isimde `.txt` formatÄ±nda aÃ§Ä±klama dosyasÄ± oluÅŸturur.

### `recommend.py`
KullanÄ±cÄ±dan bir giriÅŸ cÃ¼mlesi alÄ±r. TÃ¼m modelleri kullanarak en benzer 5 yorumu ve cosine similarity skorunu hesaplar. `model_outputs.csv` dosyasÄ±na yazar.

### `compare_models_scores.py`
`model_outputs.csv` ve `manual_scoring_filled.csv` dosyalarÄ±nÄ± birleÅŸtirir. Ortalama cosine similarity + anlamsal puan hesaplayarak `model_comparison_scores.csv` dosyasÄ±nÄ± oluÅŸturur.

### `jaccard_matrix_generator.py`
Her modelin ilk 5 Ã¶nerisini set olarak alÄ±r. 18x18 Jaccard benzerlik matrisini `jaccard_matrix.csv` dosyasÄ±na yazar.

### `save_model_table_image.py`
`model_comparison_scores.csv` tablosunu gÃ¶rselleÅŸtirir ve PNG olarak kaydeder.

---

## ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rmasÄ± Ã–zet

| Model | Avg. Cosine | Avg. Anlamsal Skor |
|-------|-------------|---------------------|
| stemmed_cbow_window2_dim300 | 0.9994 | 4.4 |
| stemmed_cbow_window2_dim100 | 0.9989 | 4.4 |
| stemmed_cbow_window4_dim100 | 0.9987 | 4.2 |

---

## ğŸ”„ Jaccard Matris Ã–zeti

- 18 modelin ilk 5 Ã¶nerisi set olarak karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±
- AynÄ± Ã¶nerileri sunan modellerin Jaccard skoru `1.0`
- Benzer olmayanlar `0.0 - 0.3` aralÄ±ÄŸÄ±nda
- Matris dosyasÄ±: `jaccard_matrix.csv`

---

## ğŸ“„ Rapor

TÃ¼m analizlerin detaylÄ± aÃ§Ä±klandÄ±ÄŸÄ± PDF raporu ÅŸu dosyadadÄ±r:

ğŸ“„ `final_nlp_project_report.pdf`

---

HazÄ±rlayan: **[Senin AdÄ±n]**  
Ders: **DoÄŸal Dil Ä°ÅŸleme**  
Tarih: [Final Teslim Tarihi]
